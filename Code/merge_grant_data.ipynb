{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIHR Grant Data Merger\n",
    "\n",
    "This notebook merges data from \"Silver\" sheets (yearly grant data) into the \"Gold\" sheet (All Recipients CMZ, PoP, CHRP) to fill in missing information such as:\n",
    "- Primary Institute (PrimaryInstituteEN_InstitutPrincipalAN)\n",
    "- Research Categories (AllResearchCategoriesEN_TousCategoriesRechercheAN)\n",
    "- Application Keywords (ApplicationKeywords_MotsClesDemande)\n",
    "\n",
    "The matching is done based on researcher names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to initialize Spark in Databricks as it's already available\n",
    "# Just check the Spark version\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data files\n",
    "gold_sheet_path = \"/Volumes/cihr/default/grant_datasets_bronze/all_recipients_cmz_pop_chrp.csv\"\n",
    "silver_dir_path = \"/Volumes/cihr/default/grant_datasets_bronze/\"\n",
    "output_path = \"/Volumes/cihr/default/grant_datasets_silver/enriched_recipients\"\n",
    "\n",
    "# List files in the silver directory\n",
    "silver_files = dbutils.fs.ls(silver_dir_path)\n",
    "excel_files = [f.path for f in silver_files if f.path.endswith('.xlsx')]\n",
    "print(f\"Found {len(excel_files)} Excel files in the silver directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Gold Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, trim, lit, when\n",
    "\n",
    "def load_gold_sheet(gold_sheet_path):\n",
    "    \"\"\"Load the Gold sheet (All Recipients CMZ, PoP, CHRP)\"\"\"\n",
    "    print(f\"Loading Gold sheet from: {gold_sheet_path}\")\n",
    "    \n",
    "    # Load the gold sheet\n",
    "    gold_df = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(gold_sheet_path)\n",
    "    \n",
    "    # Create a clean name column for matching\n",
    "    gold_df = gold_df.withColumn(\"clean_name\", \n",
    "                               lower(trim(col(\"Name\"))))\n",
    "    \n",
    "    print(f\"Gold sheet loaded with {gold_df.count()} records\")\n",
    "    return gold_df\n",
    "\n",
    "# Load the Gold sheet\n",
    "gold_df = load_gold_sheet(gold_sheet_path)\n",
    "\n",
    "# Display the first few rows and schema\n",
    "print(\"\\nGold Sheet Schema:\")\n",
    "gold_df.printSchema()\n",
    "print(\"\\nGold Sheet Sample:\")\n",
    "display(gold_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Process Silver Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_silver_file(file_path):\n",
    "    \"\"\"Process a single Silver sheet\"\"\"\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    \n",
    "    # Extract year from filename (format: cihr_investments_investissements_irsc_YYYYMM.xlsx)\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    year_str = file_name.split('_')[-1].split('.')[0]\n",
    "    fiscal_year = year_str[:4] + \"-\" + year_str[4:6]\n",
    "    \n",
    "    # Load the Excel file\n",
    "    try:\n",
    "        silver_df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .option(\"dataAddress\", \"'Sheet1'!A1\") \\\n",
    "            .load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        # Try with different sheet name\n",
    "        try:\n",
    "            silver_df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(file_path)\n",
    "        except Exception as e2:\n",
    "            print(f\"Could not load {file_path}: {e2}\")\n",
    "            return None\n",
    "    \n",
    "    # Get actual column names\n",
    "    actual_columns = silver_df.columns\n",
    "    \n",
    "    # Find name column\n",
    "    name_col = None\n",
    "    name_candidates = [\"NomineeNameEN_NomCandidatAN\", \"NomineeName_NomCandidat\"]\n",
    "    for candidate in name_candidates:\n",
    "        if candidate in actual_columns:\n",
    "            name_col = candidate\n",
    "            break\n",
    "    \n",
    "    if not name_col:\n",
    "        # Try to find any column that might contain names\n",
    "        name_candidates = [col for col in actual_columns if \"name\" in col.lower() or \"nom\" in col.lower()]\n",
    "        if name_candidates:\n",
    "            name_col = name_candidates[0]\n",
    "        else:\n",
    "            print(f\"Warning: Could not find name column in {file_path}\")\n",
    "            return None\n",
    "    \n",
    "    # Find target columns\n",
    "    target_cols = [\n",
    "        \"PrimaryInstituteEN_InstitutPrincipalAN\",\n",
    "        \"AllResearchCategoriesEN_TousCategoriesRechercheAN\",\n",
    "        \"ApplicationKeywords_MotsClesDemande\"\n",
    "    ]\n",
    "    \n",
    "    column_mapping = {}\n",
    "    for target_col in target_cols:\n",
    "        found = False\n",
    "        for actual_col in actual_columns:\n",
    "            if target_col.lower() == actual_col.lower():\n",
    "                column_mapping[target_col] = actual_col\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Warning: Could not find column {target_col} in {file_path}\")\n",
    "    \n",
    "    # Create a clean name column for matching\n",
    "    silver_df = silver_df.withColumn(\"clean_name\", \n",
    "                                    lower(trim(col(name_col))))\n",
    "    \n",
    "    # Add fiscal year column\n",
    "    silver_df = silver_df.withColumn(\"fiscal_year\", lit(fiscal_year))\n",
    "    \n",
    "    # Select only the columns we need\n",
    "    select_cols = [\"clean_name\", \"fiscal_year\"]\n",
    "    for target_col, actual_col in column_mapping.items():\n",
    "        silver_df = silver_df.withColumnRenamed(actual_col, target_col)\n",
    "        select_cols.append(target_col)\n",
    "    \n",
    "    silver_df = silver_df.select(*select_cols)\n",
    "    return silver_df\n",
    "\n",
    "# Process all silver files\n",
    "all_silver_dfs = []\n",
    "for file_path in excel_files:\n",
    "    silver_df = process_silver_file(file_path)\n",
    "    if silver_df is not None:\n",
    "        all_silver_dfs.append(silver_df)\n",
    "\n",
    "# Combine all silver dataframes\n",
    "if all_silver_dfs:\n",
    "    combined_silver_df = all_silver_dfs[0]\n",
    "    for df in all_silver_dfs[1:]:\n",
    "        combined_silver_df = combined_silver_df.unionByName(df, allowMissingColumns=True)\n",
    "    \n",
    "    print(f\"\\nCombined Silver sheets with {combined_silver_df.count()} records\")\n",
    "    print(\"\\nSilver Sheet Schema:\")\n",
    "    combined_silver_df.printSchema()\n",
    "    print(\"\\nSilver Sheet Sample:\")\n",
    "    display(combined_silver_df.limit(5))\n",
    "else:\n",
    "    print(\"No valid Silver sheets found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(gold_df, silver_df):\n",
    "    \"\"\"Merge data from Silver sheets into Gold sheet based on name matching\"\"\"\n",
    "    print(\"Merging data from Silver sheets into Gold sheet\")\n",
    "    \n",
    "    # Join the dataframes on the clean name\n",
    "    merged_df = gold_df.join(\n",
    "        silver_df,\n",
    "        gold_df[\"clean_name\"] == silver_df[\"clean_name\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # Drop the duplicate clean_name column\n",
    "    merged_df = merged_df.drop(silver_df[\"clean_name\"])\n",
    "    \n",
    "    # Fill missing values with \"Not Found\"\n",
    "    for col_name in [\"PrimaryInstituteEN_InstitutPrincipalAN\", \n",
    "                     \"AllResearchCategoriesEN_TousCategoriesRechercheAN\", \n",
    "                     \"ApplicationKeywords_MotsClesDemande\"]:\n",
    "        if col_name in merged_df.columns:\n",
    "            merged_df = merged_df.withColumn(\n",
    "                col_name, \n",
    "                when(col(col_name).isNull(), \"Not Found\").otherwise(col(col_name))\n",
    "            )\n",
    "    \n",
    "    print(f\"Merged data with {merged_df.count()} records\")\n",
    "    return merged_df\n",
    "\n",
    "# Merge the data\n",
    "if 'combined_silver_df' in locals():\n",
    "    merged_df = merge_data(gold_df, combined_silver_df)\n",
    "    \n",
    "    print(\"\\nMerged Data Schema:\")\n",
    "    merged_df.printSchema()\n",
    "    print(\"\\nMerged Data Sample:\")\n",
    "    display(merged_df.limit(5))\n",
    "    \n",
    "    # Calculate match statistics\n",
    "    total_records = merged_df.count()\n",
    "    matched_records = merged_df.filter(col(\"PrimaryInstituteEN_InstitutPrincipalAN\") != \"Not Found\").count()\n",
    "    match_percentage = (matched_records / total_records) * 100 if total_records > 0 else 0\n",
    "    \n",
    "    print(f\"\\nMatch Statistics:\")\n",
    "    print(f\"Total Records: {total_records}\")\n",
    "    print(f\"Matched Records: {matched_records}\")\n",
    "    print(f\"Match Percentage: {match_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(merged_df, output_path):\n",
    "    \"\"\"Save the merged data to a new CSV file\"\"\"\n",
    "    print(f\"Saving merged data to: {output_path}\")\n",
    "    \n",
    "    # Write the merged data to a CSV file\n",
    "    merged_df.write.format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(output_path)\n",
    "    \n",
    "    # Also save as a Delta table for better performance\n",
    "    delta_path = output_path + \"_delta\"\n",
    "    merged_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(delta_path)\n",
    "    \n",
    "    print(\"Merged data saved successfully\")\n",
    "    print(f\"CSV output: {output_path}\")\n",
    "    print(f\"Delta output: {delta_path}\")\n",
    "\n",
    "# Save the results\n",
    "if 'merged_df' in locals():\n",
    "    save_results(merged_df, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the process\n",
    "if 'merged_df' in locals():\n",
    "    print(\"\\nData Merging Process Summary:\")\n",
    "    print(f\"Gold Sheet Records: {gold_df.count()}\")\n",
    "    if 'combined_silver_df' in locals():\n",
    "        print(f\"Combined Silver Sheet Records: {combined_silver_df.count()}\")\n",
    "    print(f\"Merged Records: {merged_df.count()}\")\n",
    "    \n",
    "    # Calculate match statistics for each target column\n",
    "    for col_name in [\"PrimaryInstituteEN_InstitutPrincipalAN\", \n",
    "                     \"AllResearchCategoriesEN_TousCategoriesRechercheAN\", \n",
    "                     \"ApplicationKeywords_MotsClesDemande\"]:\n",
    "        if col_name in merged_df.columns:\n",
    "            matched = merged_df.filter(col(col_name) != \"Not Found\").count()\n",
    "            match_pct = (matched / merged_df.count()) * 100\n",
    "            print(f\"{col_name} Match Rate: {match_pct:.2f}% ({matched} records)\")\n",
    "    \n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"1. Review the merged data for accuracy\")\n",
    "    print(\"2. Consider additional data sources for missing information\")\n",
    "    print(\"3. Use the enriched data for further analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
